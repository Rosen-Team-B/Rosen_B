Project Description
Detailed Introduction to the Project
The goal of the project is to develop a software system that enables Rosen data scientists to classify a large amount of images from water pipeline inspections in an efficient way. The classes should not be predefined by the software, instead they are defined by the user’s decisions. The software system should be supported by an active learning algorithm that uses one of the VGG16 layers to vectorize images.
Project Perspective
This is a new project that does not have to replace or build on any existing systems within Rosen.

Users Regarding this Project
User profile 1: Main users
Job title: Data scientists in Rosen
Tech: Fluent in Python
Task: Given a section of the water pipeline inspection videos, make algorithms to classify images of objects.
Working style: Data scientists in Rosen work in a team per inspection video to make multiple algorithms. 2 groups per algorithm.
User profile 2: Potential users
Potentially, administrator.
Project should be built based on the knowledge of adding more users with different privileges.

Product Scope
In the section we will clarify the focus of the project and rank priorities.
Focus
The focus is on the software rather than the algorithms. 
The active learning algorithms do not need to be optimized.
Lower priorities: authentication, security, installation package.
Ranking priorities
The highest priorities to lowest: 
(P1) A must requested from Rosen 
(P2) Developers priorities - what we think should be on the website (in order for website to work smoothly) 
(P3/optional) wish list
The goal is to achieve all requirements labeled as (P1) and as many (P2) as the develop team can. Features labeled as (P3) will be implemented if time allows and the other 2 priorities have been finished. For details, please check the product requirements section.

Dependencies (given to the dev team)
Data/images to train the active learning algorithm:
(optional) Blender Asset given by Rosen
(optional) Random Videos online.
Active learning algorithm:
Python library: TBD.
One layer of the pre-trained VGG16 (Open source)
Assumptions & Definitions
AL algorithm: The active learning algorithm.
An iteration for the AL algorithm: Per training session. (Everything up until the submission to train/retrain)
Performance: Not timewise. It is the accuracy of the AL algorithm (aka always return back correct images). Or, the number of iterations until the AL algorithm is marked by the user as “done training”.

Product requirements
Functional requirements
Web application details
(P1) The software should be a web application with a user interface.
Classification details
(P1) The web app should allow the user to upload an image and the name of the target item in that image as the label. 
(P1) The web app should allow the user to submit the image-label pair to the AL algorithm to train the AL algorithm.
(optional) The web app should allow the user to define how many images the algorithm will return.
(P1) The web app should present a number of images (hardcode or (optional) user defined) pulled out from the storage. The images should have a predicted label from the AL algorithm in the form of “is_target” or “is_not_target” on each image.
(P1) The web app should allow the user to mark the predicted labels of each image correctly.  For example: Add labels to all images as “I’m_interested” or “Not_interested”. The “I’m_interested” labels should be given to images with target items in it.
(P1) The web app should allow the user to submit the images with “I’m_interested” or “Not_interested” labels back to the AL algorithm to retrain it.
(P2) The web app should allow users to identify when the AL algorithm is done training. (i.g. A “i’m done training” button.)
(optional) The web app should display information of the AL algorithm to help the user identify when the AL algorithm is done training.

